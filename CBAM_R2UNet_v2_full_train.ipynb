{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fc255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave lines below uncommented this if you get:\n",
    "# OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62dab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glomerulus import Glomerulus, Patch, KidneySampleDataset, get_glomeruli, generate_glomerulus_patches_multi, generate_random_patches_multi\n",
    "from networks import CBAM_R2UNet_v2\n",
    "from utils import read_tiff, dataset_label_mean\n",
    "from losses import bce_weighted_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024924e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47dd16eb0894289952ee654be540b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Train Images:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patipol/Documents/automated-visual-acuity-tester/speech-model/whisper_env/lib/python3.10/site-packages/rasterio/__init__.py:304: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fc31af04104deaa662832449f5fc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading Test Images:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_image_names = [\n",
    "    # 'afa5e8098',\n",
    "    # '4ef6695ce',\n",
    "    # 'c68fe75ea',\n",
    "    '26dc41664',\n",
    "    '095bf7a1f',\n",
    "    '54f2eec69',\n",
    "    '1e2425f28',\n",
    "    'e79de561c',\n",
    "    'cb2d976f4',\n",
    "    'b9a3865fc',\n",
    "    '8242609fa',\n",
    "    '0486052bb',\n",
    "    '2f6ecfcdf'\n",
    "]\n",
    "\n",
    "test_image_names = [\n",
    "    'b2dc8411c',\n",
    "    'aaa6a05cc'\n",
    "]\n",
    "\n",
    "root_dir = './images'\n",
    "\n",
    "train_images = []\n",
    "train_glomeruli = []\n",
    "test_images = []\n",
    "test_glomeruli = []\n",
    "\n",
    "for image_name in tqdm(train_image_names, desc='Loading Train Images'):\n",
    "    image_path = os.path.join(root_dir, f'{image_name}.tiff')\n",
    "    label_path = os.path.join(root_dir, f'{image_name}.json')\n",
    "    try:\n",
    "        image = read_tiff(image_path)\n",
    "        train_images.append(image)\n",
    "        \n",
    "        train_glomeruli.append(get_glomeruli(label_path,'glomerulus'))\n",
    "    except:\n",
    "        print(f'Error reading {image_name}')\n",
    "    \n",
    "for image_name in tqdm(test_image_names, desc='Loading Test Images'):\n",
    "    image_path = os.path.join(root_dir, f'{image_name}.tiff')\n",
    "    label_path = os.path.join(root_dir, f'{image_name}.json')\n",
    "    try:\n",
    "        image = read_tiff(image_path)\n",
    "        test_images.append(image)\n",
    "        \n",
    "        test_glomeruli.append(get_glomeruli(label_path,'glomerulus'))\n",
    "    except:\n",
    "        print(f'Error reading {image_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e54aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 512\n",
    "model_resolution = 128\n",
    "num_train_samples = 3000\n",
    "num_val_samples = 200\n",
    "batch_size = 100\n",
    "\n",
    "model_name = 'CBAM_R2UNet_v2_rdn_data'\n",
    "loss_name = 'Weighted_BCE_Dice'\n",
    "\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36286d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9c0f91ef774bfbbcb57273bb331d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b481e33add4d9d8bd0e9ebebdbe470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f754b08ea54bdf84c0c6d7c53cbe4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1be3728d9c14e4caba6861040ad5804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate patch samples from image\n",
    "train_patches = generate_glomerulus_patches_multi(\n",
    "    patch_size = patch_size,\n",
    "    num_patches = int(num_train_samples * 0.85),\n",
    "    glomeruli_list = train_glomeruli,\n",
    "    image_list = train_images\n",
    ") + generate_random_patches_multi(\n",
    "    patch_size = patch_size,\n",
    "    num_patches = num_train_samples - int(num_train_samples * 0.85),\n",
    "    glomeruli_list = train_glomeruli,\n",
    "    image_list = train_images\n",
    ")\n",
    "\n",
    "val_patches = generate_glomerulus_patches_multi(\n",
    "    patch_size = patch_size,\n",
    "    num_patches = int(num_val_samples * 0.85),\n",
    "    glomeruli_list = test_glomeruli,\n",
    "    image_list = test_images\n",
    ") + generate_random_patches_multi(\n",
    "    patch_size = patch_size,\n",
    "    num_patches = num_val_samples - int(num_val_samples * 0.85),\n",
    "    glomeruli_list = test_glomeruli,\n",
    "    image_list = test_images\n",
    ")\n",
    "train_dataset = KidneySampleDataset(train_patches)\n",
    "val_dataset = KidneySampleDataset(val_patches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e79b88-20b5-470f-b9e2-f78bbadd5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, prefetch_factor=1)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=8, prefetch_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfafbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2964583969706049\n"
     ]
    }
   ],
   "source": [
    "# label_mean = dataset_label_mean(train_dataset) # Offset for class imbalance\n",
    "label_mean = 0.2964583969706049\n",
    "print(label_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393e79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBAM_R2UNet_v2((model_resolution, model_resolution), (patch_size, patch_size)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1a2181-e7f9-4328-be60-21cc0d728ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('./models/CBAM_R2UNet_v2_Weighted_BCE_Dice_t1000_best_loss.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5d1071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 8.126MB\n"
     ]
    }
   ],
   "source": [
    "# Print model size\n",
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3571755b-eb71-4d8f-8585-173743123ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f072bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, label_mean, epochs=100):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    best_weights = None\n",
    "    best_loss = 10000000\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "\n",
    "    criterion = bce_weighted_dice_loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.008, weight_decay=1e-6)\n",
    "    pbar = tqdm(total=epochs, desc='Training')\n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        \n",
    "        for inputs, labels in train_dataloader:\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            # Move data to GPU\n",
    "            inputs = inputs.type(dtype)\n",
    "            labels = labels.type(dtype)\n",
    "            optimizer.zero_grad()\n",
    "            # Run model\n",
    "            outputs = model.forward(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels, [1-label_mean, label_mean]).cuda()\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_epoch_loss = running_loss / len(train_dataloader)\n",
    "        train_loss.append(train_epoch_loss)\n",
    "\n",
    "        # Val\n",
    "        model.eval()\n",
    "        running_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                # Move data to GPU\n",
    "                inputs = inputs.type(dtype)\n",
    "                labels = labels.type(dtype)\n",
    "                # Run model\n",
    "                outputs = model.forward(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels, [1-label_mean, label_mean]).cuda()\n",
    "                running_loss += loss.item()\n",
    "        val_epoch_loss = running_loss / len(val_dataloader)\n",
    "        val_loss.append(val_epoch_loss)\n",
    "        \n",
    "        # Save model every 10 epochs\n",
    "        # if (epoch+1)%10 == 0:\n",
    "        torch.save(model.state_dict(), f'./models/{model_name}_{loss_name}_t{str(num_train_samples)}_b{str(batch_size)}_{str(epoch+1)}.npz')\n",
    "            \n",
    "        # Keep track of best weights\n",
    "        if val_epoch_loss < best_loss:\n",
    "            best_loss = val_epoch_loss\n",
    "            best_weights = model.state_dict()\n",
    "            \n",
    "        pbar.set_postfix({'Train Loss': train_epoch_loss, 'Val Loss': val_epoch_loss, 'Best Val': best_loss})\n",
    "        pbar.update(1)\n",
    "    # Save weights with best loss\n",
    "    torch.save(best_weights, f'./models/{model_name}_{loss_name}_t{str(num_train_samples)}_b{str(batch_size)}_best_loss.npz')\n",
    "    return model, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca8d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a0a23763884437a905c3841823b638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, train_loss, val_loss = train(model, train_dataloader, val_dataloader, label_mean, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'./models/{model_name}_{loss_name}_t{str(num_train_samples)}_b{str(batch_size)_train_loss.json', 'w') as f:\n",
    "    json.dump(train_loss, f, indent=2) \n",
    "\n",
    "with open(f'./models/{model_name}_{loss_name}_t{str(num_train_samples)}_b{str(batch_size)_val_loss.json', 'w') as f:\n",
    "    json.dump(val_loss, f, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(200), train_loss, label='Training Loss')\n",
    "plt.plot(np.arange(200), val_loss, label='Validation Loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e09d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
